<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>Python - Category - My New Hugo Site</title>
        <link>http://example.org/categories/python/</link>
        <description>Python - Category - My New Hugo Site</description>
        <generator>Hugo -- gohugo.io</generator><language>zh-CN</language><lastBuildDate>Sat, 02 Jul 2022 14:31:00 &#43;0800</lastBuildDate><atom:link href="http://example.org/categories/python/" rel="self" type="application/rss+xml" /><item>
    <title>Scrapy 爬虫的简单使用</title>
    <link>http://example.org/posts/2022/07/scrapy-spider/</link>
    <pubDate>Sat, 02 Jul 2022 14:31:00 &#43;0800</pubDate>
    <author>Author</author>
    <guid>http://example.org/posts/2022/07/scrapy-spider/</guid>
    <description><![CDATA[简单的爬虫流程 一般的，程序向网站请求网页 程序 =========&gt; 网站 而后，网站返回网页与程序 程序 &lt;========= 网站 接着程序负责解析得到的 HTML 数据即可 Scrapy 如何扩展这一流程 程序请求网页时， scrapy 添加了中间件在双方之间 程序 =====&gt; 中间件 ======&gt; 网站 网站返回数据时，也需要通过中间件 程序 &lt;===== 中间件 &lt;====== 网站 程序解析完数据后，不会马上处理数据，而是把一个网页的数据打包成一个 Item 数据，传递给 pipeline 处理 pipeline &lt;==== item &lt;==== 程序 Scrapy 简单示例 这里以爬取美图录的图片为例(注意，我不打算用默认的 start_urls 数据) 首先我们到一个模特的主页上，比如 接下来我们要从这个 指定模特页面 上的每一个专辑上爬取图片 准备项目 安装 scrapy sudo pip3 install scrapy 创建新项目 scrapy startproject meitulu 基础设定 在 meitulu/spiders/ 下我们新建一个爬虫文件 evelyn.py class Spider(scrapy.Spider): name = &#39;evelyn&#39; 其中的 name 属性是为了调用的时候能找到爬虫位置，比如调用这个爬虫的时候，我们指定 name scrapy crawl evelyn 添加命令行参数 def __init__(self, albumUrl=None, *args, **kwargs): if albumUrl == None: raise Exception(&#39;usage: -a albumUrl=.]]></description>
</item>
</channel>
</rss>
